defaults:
  - config


model:
  model_name: ${oc.env:MODEL_NAME, deepseek-ai/deepseek-coder-1.3b-instruct}
  bf16: True
  context_length: 512
  device: cuda
  use_flash_attention: True


train:
  max_gen_length: 32 # Maximum length of generated code

  # Parameters for multi-step SFT with verification
  max_query_length: 256 # Maximum length of input query for instruction fine-tuning
  max_revision_steps: 2 # Maximum number of revisions for instruction fine-tuning + 1
  generation_batch_size: 4 # Number of proposed solutions to generate in a single batch
  execution_length_limit: 20 # Character limit for code execution output
  conda_env: "agent_env"
  mask_prompt_labels: True # When prompt labels are masked, the model is trained to predict only responses
  sample_log_frac: 0.05 # Fraction of samples to log

  # What types of training to use
  use_ntp: True
  use_fim: True

  # What to train on
  train_on_code: True
  train_on_docs: True
  train_on_doc_code: True
  train_on_practice_problems: True # Instruction fine-tuning
  train_on_verified_solutions: True

  # Trainer parameters
  trainer:
    per_device_train_batch_size: 2
    num_train_epochs: 1
    logging_steps: 1
    
  # Iterative SFT Trainer parameters for multi-step SFT with verification
  iterative_sft_trainer:
    per_device_train_batch_size: 2
    num_train_epochs: 1
    logging_steps: 1
    gradient_checkpointing: True
