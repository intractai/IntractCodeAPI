defaults:
  - config

model:
  model_name: ${oc.env:MODEL_NAME, deepseek-ai/deepseek-coder-1.3b-base} # 1.3b-instruct} # 5.7bmqa-base} # 6.7b-base}
  model_type: standard 
  bf16: True
  context_length: 768
  device: cuda
  use_flash_attention: True

train:

  # What types of training to use
  use_ntp: True
  use_fim: True

  # What to train on
  train_on_code: True
  train_on_docs: True
  train_on_doc_code: True
  train_on_practice_problems: True # Instruction fine-tuning on entire problems
  train_on_verified_solutions: True # NTP/FIM training on just the solutions

  max_retrieval_threads: 4 # Maximum number of threads to use for retriving documentation data

  # Trainer parameters
  trainer:
    per_device_train_batch_size: 3
    logging_steps: 8
    logging_strategy: steps
    num_train_epochs: 3
    optim: adamw_bnb_8bit